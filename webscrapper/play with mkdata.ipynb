{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "\n",
    "# Use find_dotenv to locate the file\n",
    "%dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_folder = \"company_transcripts/\"\n",
    "mkdata_folder = \"mkdata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "transcripts_files = [f for f in listdir(transcripts_folder) if isfile(join(transcripts_folder, f)) and f.split(\".\")[-1] == 'json']\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mkdata_files = [f for f in listdir(mkdata_folder) if isfile(join(mkdata_folder, f)) and f.split(\".\")[-1] == 'json']\n",
    "\n",
    "\n",
    "for transcripts_file in [item for item in transcripts_files if item not in mkdata_files]:\n",
    "    file = Path(f'{transcripts_folder}{transcripts_file}')\n",
    "    if file.stat().st_size >0:\n",
    "        tmp_symbol = transcripts_file.split(\".\")[0]\n",
    "        \n",
    "        df = alphavantage_timeSeriesDailyAdjusted(tmp_symbol)\n",
    "        df.to_json(f'{mkdata_folder}{transcripts_file}', orient='records')\n",
    "        \n",
    "        time.sleep(30)\n",
    "        #break\n",
    "        print(tmp_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def alphavantage_timeSeriesDailyAdjusted(symbol):\n",
    "    res = requests.get(f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&outputsize=full&apikey={os.getenv(\"ALPHAVANTAGE_API\")}')\n",
    "    \n",
    "    max_retry = 5\n",
    "    k = 0\n",
    "    while 'Meta' not in res.text:\n",
    "        print(res.content)\n",
    "        time.sleep(60)\n",
    "        res = requests.get(f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&outputsize=full&apikey={os.getenv(\"ALPHAVANTAGE_API\")}')\n",
    "        \n",
    "        k += 1\n",
    "        \n",
    "        if k >= max_retry:\n",
    "            print('unable to use API')\n",
    "            break\n",
    "        \n",
    "    \n",
    "    \n",
    "    dict_data = json.loads(res.content)\n",
    "    \n",
    "    for tmp_field in dict_data.keys():\n",
    "        if 'Meta' in tmp_field:\n",
    "            hdr_metadata = tmp_field\n",
    "        elif 'Time' in tmp_field and 'Serie' in tmp_field:\n",
    "            hdr_ts = tmp_field\n",
    "    \n",
    "        \n",
    "        \n",
    "    for tmp_field in dict_data[hdr_metadata].keys():\n",
    "        if 'Symbol' in tmp_field:\n",
    "            hdr_symbol = tmp_field\n",
    "            break\n",
    "    \n",
    "    tmp_symbol = dict_data[hdr_metadata][hdr_symbol]\n",
    "    \n",
    "    for date_tmp in dict_data[hdr_ts]:\n",
    "        data_dim = dict_data[hdr_ts][date_tmp].keys()\n",
    "        break\n",
    "    \n",
    "    for tmp_key in data_dim:\n",
    "        if 'open' in tmp_key:\n",
    "            hdr_open = tmp_key\n",
    "        elif 'high' in tmp_key:\n",
    "            hdr_high = tmp_key\n",
    "        elif 'low' in tmp_key:\n",
    "            hdr_low = tmp_key\n",
    "        elif 'close' in tmp_key and 'adjusted' not in tmp_key:\n",
    "            hdr_close = tmp_key\n",
    "        elif 'adjusted close' in tmp_key:\n",
    "            hdr_adjclose = tmp_key\n",
    "        elif 'volume' in tmp_key:\n",
    "            hdr_volume = tmp_key\n",
    "        elif 'dividend' in tmp_key:\n",
    "            hdr_dividend = tmp_key\n",
    "        elif 'split' in tmp_key:\n",
    "            hdr_split = tmp_key\n",
    "    \n",
    "    list_data = []\n",
    "\n",
    "    bridge = {\n",
    "        'open': hdr_open,\n",
    "        'high': hdr_high,\n",
    "        'low': hdr_low,\n",
    "        'close': hdr_close,\n",
    "        'adjclose': hdr_adjclose,\n",
    "        'volume': hdr_volume,\n",
    "        'div': hdr_dividend,\n",
    "        'split': hdr_split,\n",
    "    }\n",
    "\n",
    "    for tmp_date in dict_data[hdr_ts]:\n",
    "\n",
    "        if tmp_date != datetime.date.today().strftime('%Y-%m-%d'):\n",
    "\n",
    "            row = {\n",
    "                'symbol': tmp_symbol,\n",
    "                'dateeod': tmp_date,\n",
    "            }\n",
    "\n",
    "            for tmp_conv_num in bridge:\n",
    "                try:\n",
    "                    row[tmp_conv_num] = float(dict_data[hdr_ts][tmp_date][bridge[tmp_conv_num]])\n",
    "                except:\n",
    "                    row[tmp_conv_num] = None\n",
    "\n",
    "\n",
    "            list_data.append( row )\n",
    "    \n",
    "    df = pd.DataFrame(list_data)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
